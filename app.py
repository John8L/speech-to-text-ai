#v1.0.1
import os
# ç¦ç”¨ Streamlit æ–‡ä»¶ç›£è¦–ä»¥é¿å… torch å…¼å®¹æ€§å•é¡Œ
os.environ["STREAMLIT_SERVER_ENABLE_FILE_WATCHER"] = "false"

import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import tempfile
import soundfile as sf
import numpy as np
from pydub import AudioSegment
import subprocess
import sys

# è¨­ç½®ä¸Šå‚³é™åˆ¶ç‚º500MB (é©ç”¨æ–¼Streamlit Cloudç­‰ç’°å¢ƒ)
os.environ["STREAMLIT_SERVER_MAX_UPLOAD_SIZE"] = "500"

# æª¢æŸ¥ä¸¦å®‰è£å¿…è¦å¥—ä»¶
def check_and_install_packages():
    required_packages = {
        'streamlit': 'streamlit',
        'pydub': 'pydub',
        'soundfile': 'soundfile',
        'numpy': 'numpy',
        'transformers': 'transformers',
        'torch': 'torch',
        'streamlit-webrtc': 'streamlit_webrtc',
        'ffmpeg-python': 'ffmpeg'
    }
    
    missing_packages = []
    for package, import_name in required_packages.items():
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        st.warning(f"æ­£åœ¨å®‰è£ç¼ºå°‘çš„å¥—ä»¶: {', '.join(missing_packages)}...")
        for package in missing_packages:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        st.success("å¥—ä»¶å®‰è£å®Œæˆ! è«‹é‡æ–°è¼‰å…¥é é¢ã€‚")
        st.experimental_rerun()

check_and_install_packages()

# é é¢è¨­ç½®
st.set_page_config(
    page_title="èªéŸ³è½‰æ–‡å­—å·¥å…·v1.0.1",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ¤ èªéŸ³è½‰æ–‡å­—å·¥å…·")
st.markdown("""
æ­¤å·¥å…·ä½¿ç”¨OpenAIçš„Whisperæ¨¡å‹å°‡èªéŸ³è½‰æ›ç‚ºæ–‡å­—ï¼Œå®Œå…¨å…è²»ä¸”å¯åœ¨ç·šä¸Šä½¿ç”¨ã€‚
""")

# åˆå§‹åŒ–æ¨¡å‹
@st.cache_resource
def load_model():
    from transformers import pipeline
    try:
        return pipeline(
            "automatic-speech-recognition",
            model="openai/whisper-small",
            device="cpu"
        )
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è¼‰å¤±æ•—: {str(e)}")
        return None

# éŸ³è¨Šè™•ç†å‡½æ•¸
def process_audio(file_path, model):
    try:
        audio_data, sample_rate = sf.read(file_path)
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
            
        temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        sf.write(temp_wav.name, audio_data, sample_rate, format='WAV')
        
        result = model(temp_wav.name)
        os.unlink(temp_wav.name)
        return result["text"]
    except Exception as e:
        st.error(f"éŸ³è¨Šè™•ç†éŒ¯èª¤: {str(e)}")
        return None

# ä¸»æ‡‰ç”¨ç•Œé¢
def main():
    model = load_model()
    
    tab1, tab2 = st.tabs(["ğŸ“ æª”æ¡ˆä¸Šå‚³ (æœ€å¤§30ç§’)", "ğŸ¤ éŒ„éŸ³è¼¸å…¥"])
    
    with tab1:
        st.header("ğŸ“ æª”æ¡ˆä¸Šå‚³ (æœ€å¤§30ç§’)")
        uploaded_file = st.file_uploader(
            "é¸æ“‡éŸ³è¨Šæª”æ¡ˆ (WAV, MP3)",
            type=["wav", "mp3"],
            accept_multiple_files=False
        )
        
        if uploaded_file is not None:
            # é¡¯ç¤ºæª”æ¡ˆå¤§å°è³‡è¨Š
            file_size = len(uploaded_file.getvalue()) / (1024 * 1024)  # è½‰æ›ç‚ºMB
            st.info(f"æª”æ¡ˆå¤§å°: {file_size:.2f}MB")
            
            if file_size > 500:
                st.error("æª”æ¡ˆå¤§å°è¶…é500MBé™åˆ¶")
            else:
                st.audio(uploaded_file)
                
                if st.button("è½‰æ›æª”æ¡ˆ", key="file_convert"):
                    with st.spinner("è½‰æ›ä¸­ï¼Œè«‹ç¨å€™..."):
                        try:
                            # ä½¿ç”¨ getvalue() ç²å–æª”æ¡ˆå…§å®¹è€Œä¸æ˜¯ chunks()
                            file_content = uploaded_file.getvalue()
                            
                            # ä¿å­˜åˆ°è‡¨æ™‚æ–‡ä»¶
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp_file:
                                tmp_file.write(file_content)
                                tmp_path = tmp_file.name
                            
                            # è½‰æ›ç‚ºWAVæ ¼å¼
                            if uploaded_file.name.endswith('.mp3'):
                                try:
                                    audio = AudioSegment.from_mp3(tmp_path)
                                    wav_path = tmp_path + ".wav"
                                    audio.export(wav_path, format="wav")
                                    os.unlink(tmp_path)
                                except Exception as e:
                                    st.error(f"MP3è½‰æ›å¤±æ•—: {str(e)}")
                                    os.unlink(tmp_path)
                                    return
                            else:
                                wav_path = tmp_path
                            
                            # åŸ·è¡Œè½‰æ›
                            text = process_audio(wav_path, model)
                            os.unlink(wav_path)
                            
                            if text:
                                st.success("è½‰æ›æˆåŠŸ!")
                                st.text_area("è½‰æ›çµæœ", text, height=200)
                        except Exception as e:
                            st.error(f"è½‰æ›å¤±æ•—: {str(e)}")
                            if 'tmp_path' in locals() and os.path.exists(tmp_path):
                                os.unlink(tmp_path)
    
    with tab2:
        st.header("éŒ„éŸ³è¼¸å…¥")
        st.warning("æ³¨æ„: éŒ„éŸ³åŠŸèƒ½éœ€è¦ç€è¦½å™¨éº¥å…‹é¢¨æ¬Šé™")
        
        webrtc_ctx = webrtc_streamer(
            key="record_audio",
            mode=WebRtcMode.SENDONLY,
            audio_receiver_size=1024,
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"audio": True, "video": False}
        )
        
        if webrtc_ctx.audio_receiver:
            if st.button("è½‰æ›éŒ„éŸ³", key="record_convert"):
                with st.spinner("æ­£åœ¨è™•ç†..."):
                    try:
                        audio_frames = []
                        for _ in range(100):
                            frame = webrtc_ctx.audio_receiver.get_frame(timeout=1)
                            if frame: audio_frames.append(frame)
                        
                        if not audio_frames:
                            st.error("æœªæ”¶åˆ°éŸ³è¨Šæ•¸æ“š")
                            return
                            
                        audio_np = np.concatenate([f.to_ndarray() for f in audio_frames])
                        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                            sf.write(tmp_file.name, audio_np, 16000)
                            text = process_audio(tmp_file.name, model)
                            os.unlink(tmp_file.name)
                        
                        if text:
                            st.success("è½‰æ›æˆåŠŸ!")
                            st.text_area("è½‰æ›çµæœ", text, height=200)
                    except Exception as e:
                        st.error(f"è½‰æ›å¤±æ•—: {str(e)}")


    # å´é‚Šæ¬„è³‡è¨Š
    st.sidebar.markdown("""
    ### ä½¿ç”¨èªªæ˜
    1. é¸æ“‡è¼¸å…¥æ–¹å¼: ä¸Šå‚³æª”æ¡ˆæˆ–éŒ„éŸ³
    2. é»æ“Šè½‰æ›æŒ‰éˆ•
    3. æŸ¥çœ‹ä¸¦è¤‡è£½è½‰æ›çµæœ

    ### æŠ€è¡“è³‡è¨Š
    - ä½¿ç”¨OpenAI Whisperå°å‹æ¨¡å‹
    - æ”¯æ´ä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šç¨®èªè¨€
    - å®Œå…¨å…è²»é–‹æºæ–¹æ¡ˆ
    """)


if __name__ == "__main__":
    main()